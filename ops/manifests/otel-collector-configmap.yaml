# OpenTelemetry Collector Configuration
# This ConfigMap contains the OTel Collector configuration for trace collection and export.
# The collector receives traces from applications (via OTLP/Jaeger/Zipkin) and forwards them to Tempo.
# See VERSIONS.md for version tracking.
apiVersion: v1
kind: ConfigMap
metadata:
  name: otel-collector-config
  namespace: monitoring
data:
  # OTel Collector configuration file (mounted to /etc/otel-collector-config.yaml in deployment)
  otel-collector-config.yaml: |
    # Extensions: Optional functionality like health checks and authentication
    # Extensions: Optional functionality like health checks and authentication
    extensions:
      # Health check extension: HTTP endpoint for liveness/readiness probes (port 13133)
      health_check:
        endpoint: 0.0.0.0:13133
      # pprof extension: Performance profiling endpoint (port 1777)
      pprof:
        endpoint: 0.0.0.0:1777
      # zpages extension: Debugging pages for trace inspection (port 55679)
      zpages:
        endpoint: 0.0.0.0:55679
      # Basic Auth extension: Authentication for Tempo export (credentials from Secret)
      # Basic Auth for OKE Tempo (credentials injected via env vars from Secret)
      basicauth/oke:
        client_auth:
          username: ${env:GRAFANA_USERNAME}
          password: ${env:GRAFANA_PASSWORD}

    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
          http:
            endpoint: 0.0.0.0:4318
      jaeger:
        protocols:
          grpc:
            endpoint: 0.0.0.0:14250
          thrift_http:
            endpoint: 0.0.0.0:14268
          thrift_compact:
            endpoint: 0.0.0.0:6831
          thrift_binary:
            endpoint: 0.0.0.0:6832
      zipkin:
        endpoint: 0.0.0.0:9411

      # Scrape the collector's own Prometheus telemetry metrics
      prometheus:
        config:
          scrape_configs:
            - job_name: 'otel-collector'
              scrape_interval: 10s
              static_configs:
                - targets: ['localhost:8888']

    processors:
      batch:
        timeout: 1s
        send_batch_size: 1024
      memory_limiter:
        check_interval: 1s
        limit_mib: 512
      resource:
        attributes:
          - key: service.name
            value: rocket-chat
            action: upsert
          - key: service.version
            value: "1.0.0"
            action: upsert
          - key: deployment.environment
            value: production
            action: upsert
          - key: k8s.cluster.name
            value: aks-canepro
            action: upsert
          # Add cluster identifier to all traces (for filtering in Grafana Tempo)
          # AKS Migration: Updated cluster label for AKS cluster
          - key: cluster
            value: aks-canepro  # Cluster identifier (filter by this in Grafana Tempo)
            action: upsert  # Add or update this attribute on all traces
          - key: region
            value: remote
            action: upsert

    exporters:
      # Debug exporter: logs trace/metric data for debugging (replaces deprecated 'logging' exporter)
      debug:
        verbosity: basic

      # OKE Central Hub Tempo (Secure HTTP)
      # Using OTLP/HTTP is more reliable through Ingress than gRPC
      # Explicit traces_endpoint ensures the hub path is correct
      otlphttp/oke:
        endpoint: https://observability.canepro.me
        traces_endpoint: https://observability.canepro.me/v1/traces
        tls:
          insecure: false
        auth:
          authenticator: basicauth/oke

      # Expose scraped collector metrics for optional scraping on 8889 (kept for compatibility)
      prometheus:
        endpoint: "0.0.0.0:8889"

    service:
      extensions: [health_check, pprof, zpages, basicauth/oke]
      # Expose detailed internal metrics so span counters appear (otelcol_*spans*)
      telemetry:
        metrics:
          level: detailed
      pipelines:
        traces:
          receivers: [otlp, jaeger, zipkin]
          processors: [memory_limiter, batch, resource]
          exporters: [otlphttp/oke, debug]
        metrics:
          receivers: [prometheus]
          processors: [memory_limiter, batch]
          exporters: [prometheus, debug]

